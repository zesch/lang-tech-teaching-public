Википедия получает от 25 000 до 60 000 запросов страниц в секунду, в зависимости от времени суток[92]. Запрос страницы сначала передаётся внешнему уровню кэширующих серверов Squid[93]. Запросы, которые не могут быть обслужены кэшем Squid, направляются на балансирующие нагрузку сервера с запущенным ПО Linux Virtual Server, который, в свою очередь, передаёт запрос на один из веб-серверов Apache для рендеринга (перевода в HTML) страниц из базы данных. Веб-сервера доставляют страницы по запросу, выполняя рендеринг страницы для всех языковых разделов Википедии. Для увеличения скорости в дальнейшем, переведённые в HTML страницы некоторое время хранятся в распределённом кэше в памяти. Это позволяет пропустить процесс рендеринга страницы для наиболее часто запрашиваемых статей.
