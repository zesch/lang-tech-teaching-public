{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Style des gesamten Dokuments */\n",
       "#notebook-container {\n",
       "\tfont-family: \"NimbusMonL-ReguObli\";\n",
       "\tfont-size: 120%\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r die Ãœberschrift: Zentriert diese und stellt sie fett dar. */\n",
       ".headline {\n",
       "\ttext-align: center;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 185.7%\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r die Aufgabenbeschreibung. Z.B.: \"Ãœbung zum Thema...\" */\n",
       ".description {\n",
       "\ttext-align: center;\n",
       "\tfont-size: 145.7%\n",
       "}\n",
       "\n",
       "/* Hebt das Abgabedatum fett und kursiv hervor */\n",
       "#submission {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "/* Style fÃ¼r das eigentliche Thema. Z.B.: \"Intelligenz\" */\n",
       "#topic {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       ".task_description {\n",
       "\tmargin-bottom: 20px;\n",
       "}\n",
       "\n",
       "/* Hebt die Aufgabennummerierung fett hervor. */\n",
       ".task {\n",
       "\tfont-style: normal;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 120%;\n",
       "\tborder-bottom: 2px solid black;\n",
       "  background-color: #97CAEF;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 50px;\n",
       "  padding-right: 50px;\n",
       "}\n",
       "\n",
       ".subtask {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #CAFAFE;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 25px;\n",
       "  padding-right: 25px;\n",
       "}\n",
       "\n",
       ".l1 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #14A76C;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l2 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FFE400;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".l3 {\n",
       "\tfont-style: normal;\n",
       "\tfont-size: 100%;\n",
       "  background-color: #FF652F;\n",
       "  color: black;\n",
       "\tpadding: 2px;\n",
       "  padding-left: 5px;\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".points {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       "ol.lower_roman {\n",
       "    list-style-type: lower-roman;\n",
       "}\n",
       "\n",
       "ol.characters {\n",
       "    list-style-type: lower-alpha;\n",
       "}\n",
       "\n",
       "/* Style einer Code-Cell */\n",
       ".CodeMirror-code {\n",
       "\tbackground-color: #ededed\n",
       "}\n",
       "\n",
       "/* Style eines Kommentars im Code Ã¤ndern. */\n",
       ".cm-s-ipython span.cm-comment {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-atom {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-number {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Keywords Ã¤ndern */\n",
       ".cm-s-ipython span.cm-keyword {\n",
       "\tcolor: #B000B0\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-def {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Python-Variable Ã¤ndern */\n",
       ".cm-s-ipython span.cm-variable {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Property Ã¤ndern */\n",
       ".cm-s-ipython span.cm-property {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Operators Ã¤ndern */\n",
       ".cm-s-ipython span.cm-operator {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Strings Ã¤ndern */\n",
       ".cm-s-ipython span.cm-string {\n",
       "\tcolor: brown;\n",
       "}\n",
       "\n",
       "/* Style einer eingebauten Funktion Ã¤ndern (z.B. \"open\") */\n",
       ".cm-s-ipython span.cm-builtin {\n",
       "\n",
       "}\n",
       "\n",
       "/* Hebt hervor, welche Klammern zueinander passen */\n",
       ".cm-s-ipython .CodeMirror-matchingbracket {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-variable-2 {\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Language Technology / Sprachtechnologie\n",
    "<br><br>\n",
    "Wintersemester 2020/2021\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    Übung zum Thema <i id=\"topic\">\"Sentiment Analysis\"</i>\n",
    "    <br><br>\n",
    "    Deadline Abgabe: <i #id=\"submission\">none (see part 2)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)  \n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join\n",
    "import nltk\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Präsenzübung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Warm-Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 11.1:</i> <br>\n",
    "</div>\n",
    "\n",
    "Which statements are true?\n",
    "\n",
    "1. Subjective sentences generally refer to a personal opinion, emotion or judgment, whereas objective refers to factual information.\n",
    "2. Polarity denotes the orientation of the opinion expressed into positive and negative (and in some cases neutral). \n",
    "3. Sentiment analysis is a technique to recognize the polarity of a text opinion (positive, negative, neutral, both)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with SentiWordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 11.2:</i> <i class=\"l2\">L2</i> <br><br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the polarity scores (positive, negative, neutral scores) for the following lexicons using nltk SentiWordnet.\n",
    "\n",
    "1. Happy\n",
    "2. Sad\n",
    "3. Awesome\n",
    "4. Joy\n",
    "5. Fearless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('sentiwordnet')\n",
    "from nltk.corpus import sentiwordnet as swn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with the Amazon sentiment dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.3.1</i> <i class=\"l1\">L1</i> <br>\n",
    "</div>\n",
    "\n",
    "Run the following code-snippet. Explain it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(join('data', 'amazon_reviews_sentiments.tsv'), names=['Statement', 'label'], sep='\\t')\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.3.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Run the following code-snippet. Explain it. <br> Also analyse the distribution (check whether it is uniform or not)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.countplot(x=\"label\", data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.3.3</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Explain the following code snippet. Also analyse the results and provide comments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "\n",
    "statements = df[\"Statement\"]\n",
    "\n",
    "\n",
    "stops_eng = stopwords.words('english')\n",
    "fd = FreqDist()\n",
    "for statement in statements:\n",
    "    words = statement.split(\" \")\n",
    "    for word in words:\n",
    "        if word.lower() not in stops_eng:\n",
    "            if word.isalpha():\n",
    "                fd[word.lower()] += 1\n",
    "    \n",
    "    \n",
    "vocab = fd.keys()\n",
    "plt.figure(figsize=(16,5))\n",
    "fd.plot(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.3.4</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Repeat the above frequency distribution only for positive and negative sentiment statements. <br>Compare both distributions and describe your observation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_sent_stmts = df.loc[df['label'] == 1]['Statement']\n",
    "negative_sent_stmts = df.loc[df['label'] == 0]['Statement']\n",
    "\n",
    "# TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sentiment lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 11.4:</i> \n",
    "</div>\n",
    "\n",
    "Use existing lexical resources and machine learning algorithms to generate the classifier and test it on a separate held out set. Compare their performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.4.1</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Split the dataset into train and test set (use the last 200 records for the test set)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[\"label\"]\n",
    "train_statements =  #TODO\n",
    "train_labels = #TODO\n",
    "test_statements = #TODO\n",
    "test_labels = #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.4.1</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Download the sentiment lexicons list from <br><br> \n",
    "https://hlt-nlp.fbk.eu/technologies/sentiwords <br><br> \n",
    "You need to fill out the form to download the list and create a python dictonary which holds lexicons as key and sentiment score as value. <br>\n",
    " *Note*: the sentiment score will vary from -1 to 1 (negative sentiment to positive sentiment).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "\n",
    "senti_dict = {}\n",
    "with codecs.open('SentiWords_1.1.txt', 'r', 'utf-8') as senti_words:\n",
    "    #TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.4.2</i> <i class=\"l2\">L2</i> <br>\n",
    "</div>\n",
    "\n",
    "Explain the following code and analyse the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_senti_scores= []\n",
    "for stmt in test_statements:\n",
    "    senti_pred = []\n",
    "    for w in nltk.word_tokenize(stmt):\n",
    "        if w.lower() in senti_dict.keys():\n",
    "            senti_pred.append(senti_dict[w.lower()])\n",
    "        else:\n",
    "            senti_pred.append(0.0)\n",
    "    lexicon_senti_scores.append(np.sum(np.array(senti_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.4.3</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Convert average scores into prediction scores: <br>\n",
    "* Use a prediction score of 1 if the average sentiment score is greater than 0 \n",
    "* use 0 if the sentiment score is less than 0\n",
    "* else use 2. <br><br>\n",
    "Print the first ten rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lexicon_senti_pred = []\n",
    "\n",
    "for score in lexicon_senti_scores:\n",
    "    # TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.4.4</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Determine the confusion matrix, accuracy score and classification report based on prediction and gold labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(confusion_matrix(#TODO))\n",
    "print(accuracy_score(#TODO))\n",
    "print(classification_report(#TODO))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "   <i class=\"subtask\">11.4.5</i> <i class=\"l3\">L3</i> <br>\n",
    "</div>\n",
    "\n",
    "Find three statements that the classifier fails. <br>\n",
    "Please run the following code to test the classifier and give a justification for the classifier failure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process user input. Processing continues until the user says goodbye. \n",
    "text = \"\"\n",
    "while text != \"goodbye\":\n",
    "    # Read user input\n",
    "    text = input()\n",
    "    prediction_score = []\n",
    "    for word in text.split(' '):\n",
    "        if word.lower() in senti_dict.keys():\n",
    "            prediction_score.append(senti_dict[word.lower()])\n",
    "        else:\n",
    "            prediction_score.append(0.0)\n",
    "    if np.mean(prediction_score) > 0:\n",
    "        predition = \"Positive Sentiment\"\n",
    "    elif np.mean(prediction_score) < 0:\n",
    "        predition = \"Negative sentiment\"\n",
    "    else:\n",
    "        predition = \"Neutral\"\n",
    "    \n",
    "    print(predition)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "nlp-env",
   "language": "python",
   "name": "nlp-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
