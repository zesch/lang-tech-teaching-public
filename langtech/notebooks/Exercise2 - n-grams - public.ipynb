{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>/* Style des gesamten Dokuments */\n",
       "#notebook-container {\n",
       "\tfont-family: \"NimbusMonL-ReguObli\";\n",
       "\tfont-size: 120%\n",
       "}\n",
       "\n",
       "/* Style für die Überschrift: Zentriert diese und stellt sie fett dar. */\n",
       ".headline {\n",
       "\ttext-align: center;\n",
       "\tfont-weight: bold;\n",
       "\tfont-size: 185.7%\n",
       "}\n",
       "\n",
       "/* Style für die Aufgabenbeschreibung. Z.B.: \"Übung zum Thema...\" */\n",
       ".description {\n",
       "\ttext-align: center;\n",
       "\tfont-size: 145.7%\n",
       "}\n",
       "\n",
       "/* Hebt das Abgabedatum fett und kursiv hervor */\n",
       "#submission {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       "/* Style für das eigentliche Thema. Z.B.: \"Intelligenz\" */\n",
       "#topic {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       ".task_description {\n",
       "\n",
       "}\n",
       "\n",
       "/* Hebt die Aufgabennummerierung fett hervor. */\n",
       ".task {\n",
       "\tfont-style: normal;\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "\n",
       ".points {\n",
       "\tfont-style: italic;\n",
       "}\n",
       "\n",
       "ol.lower_roman {\n",
       "    list-style-type: lower-roman;\n",
       "}\n",
       "\n",
       "ol.characters {\n",
       "    list-style-type: lower-alpha;\n",
       "}\n",
       "\n",
       "/* Style einer Code-Cell */\n",
       ".CodeMirror-code {\n",
       "\tbackground-color: #ededed\n",
       "}\n",
       "\n",
       "/* Style eines Kommentars im Code ändern. */\n",
       ".cm-s-ipython span.cm-comment {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-atom {\n",
       "\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-number {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style eines Python-Keywords ändern */\n",
       ".cm-s-ipython span.cm-keyword {\n",
       "\tcolor: #B000B0\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-def {\n",
       "\n",
       "}\n",
       "\n",
       "/* Style einer Python-Variable ändern */\n",
       ".cm-s-ipython span.cm-variable {\n",
       "\t\n",
       "}\n",
       "\n",
       "/* Style einer Property ändern */\n",
       ".cm-s-ipython span.cm-property {\n",
       "\t\n",
       "}\n",
       "\n",
       "/* Style eines Python-Operators ändern */\n",
       ".cm-s-ipython span.cm-operator {\n",
       "\t\n",
       "}\n",
       "\n",
       "/* Style eines Python-Strings ändern */\n",
       ".cm-s-ipython span.cm-string {\n",
       "\tcolor: brown;\n",
       "}\n",
       "\n",
       "/* Style einer eingebauten Funktion ändern (z.B. \"open\") */\n",
       ".cm-s-ipython span.cm-builtin {\n",
       "\t\n",
       "}\n",
       "\n",
       "/* Hebt hervor, welche Klammern zueinander passen */\n",
       ".cm-s-ipython .CodeMirror-matchingbracket {\n",
       "\t\n",
       "}\n",
       "\n",
       ".cm-s-ipython span.cm-variable-2 {\n",
       "\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.core.display import HTML\n",
    "\n",
    "HTML(\"<style>\" + open(\"style.css\").read() + \"</style>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"headline\">\n",
    "Language Technology / Sprachtechnologie\n",
    "<br><br>\n",
    "Wintersemester 2019/2020\n",
    "</div>\n",
    "<br>\n",
    "<div class=\"description\">\n",
    "    Übung zum Thema <i id=\"topic\">\"N-grams\"</i>\n",
    "    <br><br>\n",
    "    Deadline Abgabe: <i #id=\"submission\">Thursday, 31.10.2019 (23:55 Uhr)</i>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Präsenzübung\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Organization\n",
    "\n",
    "Each week you will receive a handout with some theoretical and/ or programming tasks related to NLP. You can also work on them at home, but be aware that in the practice class you have the opportunity to discuss and ask questions. <br>\n",
    "Each handout also contains homework. Working on these homework tasks and handing them in is not mandatory, but you can benefit from that in two ways: You get feedback on your solutions and a better understanding of the subject, and, more importantly, you have the chance to improve your final grade for the exam. If you hand in your solutions, we will grade them based on their quality. For each homework task there are points to collect depending on the amount\n",
    "of work you have to put into it. You will find the maximum number of points to gain for a task in its header. <br>\n",
    "Finally, if you want to hand in your solutions, please use the Moodle system. Please only submit Jupyter notebooks.\n",
    "The deadline for the homework is Thursday. Later submissions will not be graded.\n",
    "\n",
    "\n",
    "### Installation\n",
    "\n",
    "In order to be able to complete the exercises and the homework, you need to install Python (http://www.python.org) and Jupyter (https://jupyter.org). \n",
    "As we are working with the Natural Language Toolkit (NLTK), please also install NLTK (http://www.nltk.org) and its packages.\n",
    "\n",
    "For further information also refer to: <br>\n",
    "https://www.nltk.org/install.html <br>\n",
    "http://www.nltk.org/data.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.probability import ConditionalFreqDist\n",
    "from nltk.corpus import*\n",
    "from nltk.book import*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Warm Up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.1:</i> <br>\n",
    "</div>\n",
    "\n",
    "Discuss in which of the following cases a frequency distribution may be used reasonably:\n",
    "1. To save a list of tokens.\n",
    "2. To count, how often each word type occurs in a given document.\n",
    "3. To find collocations in a text.\n",
    "4. To count, how often adjectives, nouns or verbs occur in a given text.\n",
    "5. To compute the number of occurrences of each item in a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.2:</i> <br>\n",
    "</div>\n",
    "\n",
    "Discuss in which of the following cases a conditional frequency distribution may be used reasonably:\n",
    "1. To count how often each word type occurs in a given document, which belongs to a given category.\n",
    "2. To find collocations in a text.\n",
    "3. To count how often adjectives, nouns or verbs occur in a given text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.3:</i> <br>\n",
    "</div>\n",
    "\n",
    "Token/Type/Vocabulary: Which of the following statements are true?\n",
    "1. Every token is a type.\n",
    "2. The vocabulary of a text consists of all tokens.\n",
    "3. The vocabulary of a text consists of all types.\n",
    "4. The vocabulary of a text consists of the union of all tokens and all types.\n",
    "5. The vocabulary of a text consists of the intersection of all tokens and all types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.4:</i> <br>\n",
    "</div>\n",
    "\n",
    "Lists in Python: Let l and m be lists of words. Which of the following lines are syntactically correct?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1: l.index(\"hi\") \n",
    "#2: [l] - 2\n",
    "#3: x = 1 + m\n",
    "#4: x = 1 & m\n",
    "#5: l[1,4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.5:</i> <br>\n",
    "</div>\n",
    "\n",
    "Explore some texts provided by NLTK (to avoid slow reactions do the following with a sublist of text1, i.e.\n",
    "t = text1[:500]) and explain the meaning of the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = text1[:500]\n",
    "print(str(\"len:\"),len(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sorted(t):\",sorted(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"set(t):\",set(t))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"sorted(set(t)):\",sorted(set(t)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"len(set(t)):\",len(set(t)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find out which types of the sentence \"Today it's nice weather. Is it not nice today :-)?\" are contained in the Chat Corpus of NLTK."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.6:</i> <br>\n",
    "</div>\n",
    "\n",
    "*Task 2.6.1:* Explain the following function, what does it compute? (Level 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [w for w in text1.tokens if w.lower().startswith('e')]\n",
    "print(set(words[:10]))\n",
    "print('count:', len(words))\n",
    "print('count:', len(set(words)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.6.2:* Change the function above so that it extracts all words from a corpus that start and end with the letter 's' and consists out of 4 letters, the output should contain all found words and the count of them. (Level 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.6.3:* Another way of finding interesting tokens in a corpus is to see which ones do not occur in another corpus. Write a method that prints all tokens that only appear in a certain corpus, given another corpus. (Level 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frequency Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.7:</i> <br>\n",
    "</div>\n",
    "\n",
    "*Task 2.7.1:* Use a frequency distribution and print the vocabulary of Moby Dick (text1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.7.2:* Find the 20 most and least frequent words in Moby Dick (text1). Using the command fdist.hapaxes() you can also find words that only appear once (hapaxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.8:</i> <br>\n",
    "</div>\n",
    "\n",
    "\n",
    "*Task 2.8.1:* Write a funtion that computes how many times the word \"lol\" appears in the chat corpus (text 5) and how much this is as a percentage of the total number of words in this text. (Level 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.8.2:* Adapt the code from task 2.6.1 to find the 20 most common words in a corpus starting with 'th'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.8.3:* We can also look at the distribution of word lengths in a text by creating a FreqDist out of a list of numbers, with each number being the length of the corresponding word in the text. <br>\n",
    "Compare the count and frequency of the most frequent word length in Moby Dick (text1) to those in Monty Python and the Holy Grail (text7)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Frequency Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.9:</i> <br>\n",
    "</div>\n",
    "\n",
    "Write a function get_word_frequency that extracts the most frequent word with `n` letters from a corpus `c`. (Level 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.10:</i> <br>\n",
    "</div>\n",
    "\n",
    "One of the corpora in DKPro Toolbox is the US Presidential Inaugural Addresses. An interesting property of\n",
    "this collection is its time dimension: The corpus contains an address for each president."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.10.1:* Take a look at the function below. Without executing the code on your PC, describe what the resulting chart shows. Then execute it to verify your answer. (Level 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inaugural.fileids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfd = nltk.ConditionalFreqDist((len(w), fileid[:4])\n",
    "    for fileid in inaugural.fileids()\n",
    "    for w in inaugural.raw(fileid))\n",
    "cfd.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.10.2:* Enhance the function above so that it plots the number of distinct tokens (without duplicates) for each speech. (Level 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.10.3:* Let’s look at how the words “America” and “citizen” are used over time. Use a CFD and plot how often each of those two words are used in each inaugural address. (Level 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.11:</i> <br>\n",
    "</div>\n",
    "\n",
    "*Task 2.11.1:* Pick 20 first names randomly – male and female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.11.2:* Fill in the table below: <br>\n",
    "\n",
    "| - | male   | female | sum\n",
    "|------|------|------|-----\n",
    "|  ends in 'a' | ? | ? | ?\n",
    "|  ends not with an 'a' | ? | ? | ?\n",
    "|  sum | ? | ? | ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.11.3:* Calculate the probability, that a name which ends in ’a’ is a female name."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.11.4* Use the conditional frequency distribution over the Names corpus to verify the hypothesis that first names ending with an ‘a’ are most likely female. (Level 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.12:</i> <br>\n",
    "</div>\n",
    "\n",
    "Using the given conditional frequency distribution over bigrams from the Brown corpus, complete the method\n",
    "generateSentence so that it generates sentences given a certain target word. Then change the underlying corpus\n",
    "(e.g. use the Book of Genesis corpus) and compare the results. (Level 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.13:</i> <br>\n",
    "</div>\n",
    "\n",
    "Compute the probability of the sentence \"the city is old\" under bigram models from two different nltk corpora. Under which corpus is the sentence more probable? Can you find (trial and error) a sentence that is more likely for the other corpus without being directly contained in it?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.14:</i> <br>\n",
    "</div>\n",
    "\n",
    "Consider the following text: “Today it’s nice weather. Is it not nice today :-) ?” <br>\n",
    "1. What is the length of this text? What may be counted?\n",
    "2. What are reasonable tokens?\n",
    "3. State the types and the vocabulary of this short text according to your chosen tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Task 2.15:</i> <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.15.1:* Take a look at the code below. Without executing it on your computer, what is the output? (Level 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \"Hello. This is a text. A text that contains sentences, which contain words. It has no greater meaning!\"\n",
    "for stc in nltk.sent_tokenize(s):\n",
    "    print(stc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.15.2:* Change the function above so that it extracts all tokens contained in String s. (Hint: Use the segmenter!) (Level 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.15.3:* Change the document in order to make it particularly difficult for the tokenizer to work correctly. Run it again and check how well it performed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hausübung"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 2.1:</i>\n",
    "        ::: 6 Homework points :::</div>\n",
    "\n",
    "Implement a language guesser, i.e. a function that takes a given text and outputs the language it thinks the text is written in. The function should base its decision on the frequency of individual characters in each language."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.1.1:* Implement a function get_language_cfd(languages, words) which takes a list of languages as an argument and returns a conditional frequency distribution where:\n",
    "* the languages are the conditions\n",
    "* the values are the lower case characters found in the words for each language <br>\n",
    "Inside the function you can access the UDHR corpus to get samples for several languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.1.2:* Develop an algorithm which calculates the overall score of a given text based on the frequency of characters accessible by language_model_cfd[language].freq(character). Implement a function guessLanguage that returns the most likely language for a given text according to your algorithm from the previous sub task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.1.3:* Test your implementation with the data text1, text2 and text3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If your function does not detect the correct language for at least two of these sentences, improve your algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_language_cfd(languages, words):\n",
    "    \"\"\"Build a ConditionalFrequencyDistribution of character frequencies in the UDHR corpus conditioned \n",
    "    on each language\"\"\"\n",
    "    \n",
    "\n",
    "def guess_language(language_model_cfd, text):\n",
    "    \"\"\"Returns the guessed language for the given text\"\"\"\n",
    "\n",
    "    \n",
    "languages = ['English', 'German_Deutsch', 'French_Francais']\n",
    "# build the language models\n",
    "# udhr contains the Universal Declaration of Human Rights in over 300 languages\n",
    "language_base = dict((language, udhr.words(language + '-Latin1')) for language in languages)\n",
    "language_model_cfd = get_language_cfd(languages, language_base)\n",
    "\n",
    "# print the models for visual inspection (you always should have a look at the data :)\n",
    "for language in languages:\n",
    "    for key in language_model_cfd[language].keys():\n",
    "        print(language, key, \"->\", language_model_cfd[language].freq(key))\n",
    "  \n",
    "text1 = \"Peter had been to the office before they arrived.\"\n",
    "text2 = \"Si tu finis tes devoirs, je te donnerai des bonbons.\"\n",
    "text3 = \"Das ist ein schon recht langes deutsches Beispiel.\"\n",
    "\n",
    "# guess the language by comparing the frequency distributions\n",
    "print()\n",
    "print(guess_language(language_model_cfd, text1)) # English 2.88\n",
    "print()\n",
    "print(guess_language(language_model_cfd, text2)) # French_Francais 2.74\n",
    "print()\n",
    "print(guess_language(language_model_cfd, text3)) # German_Deutsch 3.03"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.1.4:* Discuss why English and German texts are difficult to distinguish with the given approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 2.2:</i>\n",
    "        ::: 4 Homework points :::</div>\n",
    "\n",
    "The previous language guesser was based on the frequency of characters. Implement alternative language guesser based on the following lexical units:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.2.1* tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.2.2* character bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Task 2.2.3* token bigrams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"task_description\">\n",
    "    <i class=\"task\">Homework 2.3:</i>\n",
    "        ::: 1 extra exam bonus point :::</div>\n",
    "\n",
    "We will evaluate your system on unknown data. It will be similar in nature to the bigger training data provided in Moodle. 1 extra exam bonus point will be awarded to the 3 teams who submitted the best system. The final results will be presented in the lecture."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
